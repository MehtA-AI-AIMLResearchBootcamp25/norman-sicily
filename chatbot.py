# -*- coding: utf-8 -*-
"""chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oFh-cE-1XrHPZjpCRP9yKkKT-kBpWsIq

# Import Libraries + Download Packages
"""

import pandas as pd
import numpy as np
from langchain.tools import tool
from langchain.agents import AgentType, initialize_agent, Tool
from langchain.chains import LLMChain
from langchain_openai import AzureChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.agents import ZeroShotAgent
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.tools import StructuredTool
from langchain.prompts import ChatPromptTemplate
from langchain.vectorstores import Chroma
from pydantic import BaseModel


"""# Preprocessing Data"""

people_to_places_df = pd.read_csv("/Users/nischithsrikanth/Desktop/norman sicily/people_to_places.csv")
places_to_places_df = pd.read_csv("/Users/nischithsrikanth/Desktop/norman sicily/places_to_places.csv")

"""# Embeddings"""

def initialize_chroma_db(documents, embedding_model):
    """Initialize a ChromaDB vector store with the given documents."""
    return Chroma.from_documents(documents=documents, embedding=embedding_model)

"""# LLM"""

#Query Function

def run_query(dataframe_name: str, query: str) -> str:
    try:
        df_map = {
            "people_to_places_df": people_to_places_df,
            "places_to_places_df": places_to_places_df,
        }
        df = df_map[dataframe_name]
        result = eval(query, {"df": df})

        if isinstance(result, pd.Series):
            result = result.reset_index()
            result.columns = ['Label', 'Count']
            return result.to_string(index=False)

        elif isinstance(result, pd.DataFrame):
            return result.to_string(index=False)

        else:
            return str(result)

    except Exception as e:
      return f"ERROR: {str(e)}"

class RunQueryInputSchema(BaseModel):
    dataframe_name: str
    query: str

#RAG Function
def search_vector_store(query: str, k: int) -> str:
    """Search the vector store for relevant documents."""
    try:
        docs = vector_store.similarity_search(query, k=k)
        results = "\n\n".join([f"Document {i+1}:\n{doc.page_content}" for i, doc in enumerate(docs)])
        return results
    except Exception as e:
        return f"ERROR: {str(e)}"

class SearchVectorStoreInputSchema(BaseModel):
    query: str
    k: int

def get_chatbot_response(user_input):
    llm = AzureChatOpenAI(
        azure_deployment= "---",
        openai_api_version= "---",
        azure_endpoint= "---",
        api_key= "---",
        temperature=0,
    )

    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    sample_docs = TextLoader("/Users/nischithsrikanth/Desktop/norman sicily/combined_output.txt").load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
    sample_docs = text_splitter.split_documents(sample_docs)

    global vector_store
    vector_store = initialize_chroma_db(sample_docs, embeddings)

    tools = [
        StructuredTool.from_function(
            name="run_query_tool",
            func=run_query,
            description="Runs a generated pandas query on a dataframe",
            args_schema=RunQueryInputSchema
        ),
        StructuredTool.from_function(
            name="search_documents",
            func=search_vector_store,
            description="Search for relevant information in the document database",
            args_schema=SearchVectorStoreInputSchema
        )
    ]

    query_prompt = """You are a helpful AI assistant that can infer the database needed and the specific query needed.
When the user asks you a specific question, use the query tool. If the user asks you a general, open-ended question, use the search documents tool.
The run query tool takes in a dataframe and a pandas query.
The search documents tool take in sample documents and an integer to identify related documents.
Always use the tool when you think the question can be answered using the tool.
Provide clear and concise responses.
The following dataframes and columns are listed below.

1. people_to_places_df with columns:
- Site Type
- Site Name (Italian)
- Site Name (English)
- Modern Municipality
- Modern Province
- Historical Region
- Geographic Coordinates
- Elevation (meters)
- Monastic Affiliation
- Person Name
- Person Name Variants
- Person Gender
- Person Title or Role
- Site Dedication Subject(s)

2. places_to_places_df with columns:
- Source Site Type
- Target Site Type
- Source Site Name (Italian)
- Source Site Name (English)
- Source Modern Municipality
- Source Modern Province
- Source Historical Region
- Source Site Dedication Subject(s)
- Source Monastic Affiliation
- Target Site Name (Italian)
- Target Site Name (English)
- Target Modern Municipality
- Target Modern Province
- Target Historical Region
- Target Site Dedication Subject(s)

When using the run_query_tool, make sure to provide both the dataframe_name and the query as separate arguments.
For example: run_query_tool(dataframe_name="people_to_places_df", query="df['Monastic Affiliation'].value_counts().idxmax()"

Give the user a detailed paragraph answer.

Question: {input}
"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", query_prompt),
        ("placeholder", "{agent_scratchpad}")
    ])

    agent = create_openai_functions_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)

    result = agent_executor.invoke({"input": f"{user_input}"})
    return result["output"]

